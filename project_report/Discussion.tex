\section{Discussion}

We see that our hybrid decision tree algorithm performs better than decision trees with plurality-labeling. Intuitively, this makes sense as it takes advantage of impure leaves (that is, leaves that are associated with subsets of training data that have multiple distinct class labels) by finding an example similar to the one we are attempting to classify. It is also unsurprising that the hybrid algorithm performs better with more examples. As the decision tree trains on more examples, it is more likely to have a similar example stored in the $k$-d tree of the appropriate decision tree leaf node.

Interestingly, the standard version of C4.5 performs quite poorly on our data. Possible reasons for this may be noise in the data or overfitting. Also, as noted by Quinlan in \cite{quinlan1996improved}, some researchers have found that C4.5 performs worse in learning settings with large numbers of continuous attributes than it does in learning settings with mainly discrete attributes. In that same work, Quinlan proposed modifications to C4.5 for improving its performance with continuous attributes. These modifications resulted in smaller decision trees and better accuracy. Future work might examine how the performance of our hybrid approach compares to that of the modified C4.5 learning algorithm.  Additionally, it may be possible to combine the two approaches.

While our algorithm performs well in terms of accuracy, precision, and recall, it is inefficient in terms of time. We combine a ``lazy'' learning algorithm with an ``eager'' one, yielding an algorithm with both long training times and long classifying times.

We made two implementation decisons that could be parametrized in future work: (1) the number of components for PCA; and (2) the size of the tuning set. We might be able to improve our algorithm by doing a grid search over these parameters. Other algorithms on the same dataset have been able to achieve excellent performance with smaller numbers of components.  For example, LeCun et al. achieved 96.7\% accuracy on the MNIST dataset after training a classifier with only 40 features after PCA \cite{lecun1998gradient}.

On the systems end, we might look into improving the efficiency of our algorithm. For example, we might try to reduce the number of examples stored in each leaf node by doing edited instance-based learning, or we might incorporate other distance measures into our $k$-NN implementation such as Hamming distance, which would allow us to incorporate discrete attributes into our algorithm.

Finally, future work should look into how this algorithm performs in other learning settings and problem domains and identify those areas in which it performs best.
